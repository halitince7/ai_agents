{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Agents, the System Message also gives information about the available tools, provides instructions to the model on how to format the actions to take, and includes guidelines on how the thought process should be segmented.\n",
    "\n",
    "A conversation consists of alternating messages between a Human (user) and an LLM (assistant).\n",
    "\n",
    "Chat templates help maintain context by preserving conversation history, storing previous exchanges between the user and the assistant. This leads to more coherent multi-turn conversations.\n",
    "\n",
    "For example:\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"I need help with my order\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'd be happy to help. Could you provide your order number?\"},\n",
    "    {\"role\": \"user\", \"content\": \"It's ORDER-123\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we just explained, we always concatenate all the messages in the conversation and pass it to the LLM as a single stand-alone sequence. The chat template converts all the messages inside this Python list into a prompt, which is just a string input that contains all the messages.\n",
    "\n",
    "For example, this is how the SmolLM2 chat template would format the previous exchange into a prompt:\n",
    "\n",
    "<|im_start|>system\n",
    "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
    "<|im_start|>user\n",
    "I need help with my order<|im_end|>\n",
    "<|im_start|>assistant\n",
    "I'd be happy to help. Could you provide your order number?<|im_end|>\n",
    "<|im_start|>user\n",
    "It's ORDER-123<|im_end|>\n",
    "<|im_start|>assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the same conversation would be translated into the following prompt when using Llama 3.2:\n",
    "\n",
    "<|begin_of_text|>\n",
    "\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 10 Feb 2025<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "I need help with my order<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "I'd be happy to help. Could you provide your order number?<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "It's ORDER-123<|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, chat templates are essential for structuring conversations between language models and users. They guide how message exchanges are formatted into a single prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful chatbot.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Hi there!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Hello, human!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Can I ask a question?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful chatbot.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Hi there!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Hello, human!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Can I ask a question?<|eot_id|>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One crucial aspect of AI Agents is their ability to take actions. As we saw, this happens through the use of Tools.\n",
    "\n",
    "In this section, we’ll learn what Tools are, how to design them effectively, and how to integrate them into your Agent via the System Message.\n",
    "\n",
    "By giving your Agent the right Tools—and clearly describing how those Tools work—you can dramatically increase what your AI can accomplish. Let’s dive in!\n",
    "\n",
    "What are AI Tools?\n",
    "\n",
    "A Tool is a function given to the LLM. This function should fulfill a clear objective.\n",
    "\n",
    "Here are some commonly used tools in AI agents:\n",
    "\n",
    "Tool\tDescription\n",
    "Web Search\tAllows the agent to fetch up-to-date information from the internet.\n",
    "Image Generation\tCreates images based on text descriptions.\n",
    "Retrieval\tRetrieves information from an external source.\n",
    "API Interface\tInteracts with an external API (GitHub, YouTube, Spotify, etc.).\n",
    "Those are only examples, as you can in fact create a tool for any use case!\n",
    "\n",
    "A good tool should be something that complements the power of an LLM.\n",
    "\n",
    "For instance, if you need to perform arithmetic, giving a calculator tool to your LLM will provide better results than relying on the native capabilities of the model.\n",
    "\n",
    "Furthermore, LLMs predict the completion of a prompt based on their training data, which means that their internal knowledge only includes events prior to their training. Therefore, if your agent needs up-to-date data you must provide it through some tool.\n",
    "\n",
    "For instance, if you ask an LLM directly (without a search tool) for today’s weather, the LLM will potentially hallucinate random weather.\n",
    "\n",
    "Weather\n",
    "A Tool should contain:\n",
    "\n",
    "A textual description of what the function does.\n",
    "A Callable (something to perform an action).\n",
    "Arguments with typings.\n",
    "(Optional) Outputs with typings.\n",
    "How do tools work?\n",
    "\n",
    "LLMs, as we saw, can only receive text inputs and generate text outputs. They have no way to call tools on their own. What we mean when we talk about providing tools to an Agent, is that we teach the LLM about the existence of tools, and ask the model to generate text that will invoke tools when it needs to. For example, if we provide a tool to check the weather at a location from the Internet, and then ask the LLM about the weather in Paris, the LLM will recognize that question as a relevant opportunity to use the “weather” tool we taught it about. The LLM will g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
